train:
  experiment_name: "EF_(FL,CE,FL)_(240,240)"
  augmentation: CustomAugmentation2 # "data augmentation type (default: BaseAugmentation)"
  batch_size: 64 # "input batch size for training (default: 64)"
  criterion1: focal # "criterion type (default: cross_entropy)" label_smoothing
  criterion2: cross_entropy # "criterion type (default: cross_entropy)" label_smoothing
  criterion3: focal # "criterion type (default: cross_entropy)"
  data_dir: /opt/ml/input/data/train/images # null
  dataset: MaskMultiLabelDataset # "dataset augmentation type (default: MaskBaseDataset)"
  epochs: 15 # "number of epochs to train (default: 1)"
  log_interval: 20 # "how many batches to wait before logging training status"
  lr: 0.001 # "learning rate (default: 1e-3)"
  lr_decay_step: 5 # "learning rate scheduler decay step (default: 20)"
  model: EfficientnetB1_MD2 # "model type (default: BaseModel)"
  model_dir: ./model # null
  name: exp # "model save at {SM_MODEL_DIR}/{name}"
  optimizer: AdamW # null
  resize: # "resize size for image when training"
    - 240
    - 240
  crop_size:
    - 320
    - 256
  seed: 444 # "random seed (default: 42)"
  val_ratio: 0.2 # "ratio for validaton (default: 0.2)"
  valid_batch_size: 64 # "input batch size for validing (default: 1000)"
  loss_rate: # loss 1 / loss 2 / loss 3
    - 0.8
    - 1
    - 1.7
  scheduler: "StepLR"
  project: "mask_cls"
  entity: "cv17"
valid:
  batch_size: 64 # "input batch size for validing (default: 1000)"
  resize: # "resize size for image when you trained (default: (96, 128))"
    - 240
    - 240
  model: EfficientnetB1_MD2 # "model type (default: BaseModel)"
  data_dir: /opt/ml/input/data/eval
  model_dir: /opt/ml/code/model/EF_(FL,CE,FL)_(240,240)2
  output_dir: /opt/ml/code/model/EF_(FL,CE,FL)_(240,240)2
